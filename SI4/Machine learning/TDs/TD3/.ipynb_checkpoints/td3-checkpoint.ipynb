{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP réseaux de neurones\n",
    "\n",
    "Diane Lingrand (diane.lingrand@univ-cotedazur)\n",
    "\n",
    "Polytech SI4 - CVML - 2020-21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports nécessaires pour la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.utils\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "nbClasses = 10 # 10 digits from 0 to 9\n",
    "# flatten the images...\n",
    "xTrain = x_train.reshape(60000, 784)\n",
    "xTest = x_test.reshape(10000, 784)\n",
    "# ... and normalize the data (grey levels are integers from 0 to 255)\n",
    "xTrain = xTrain.astype('float32')/255\n",
    "xTest = xTest.astype('float32')/255\n",
    "\n",
    "# original labels corresponds to digits. We transform the labels to categorical labels.\n",
    "yTrain = tensorflow.keras.utils.to_categorical(y_train, nbClasses)\n",
    "yTest = tensorflow.keras.utils.to_categorical(y_test, nbClasses)\n",
    "\n",
    "print('shape of yTrain :', yTrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case of binary classification\n",
    "\n",
    "# you can change the classes\n",
    "class1 = 4\n",
    "class2 = 8\n",
    "nameClass1 = '4'\n",
    "nameClass2 = '8'\n",
    "\n",
    "## TRAIN\n",
    "#class 1: positives\n",
    "x_train1 = xTrain[y_train==class1,:]\n",
    "#class 2: negatives\n",
    "x_train2 = xTrain[y_train==class2,:]\n",
    "# merging the 2 classes and shuffle\n",
    "x_trainBinaire = np.append(x_train1,x_train2,axis=0)\n",
    "y_trainBinaire = np.append(np.full(len(x_train1),-1), np.full(len(x_train2),1))\n",
    "(x_trainBinaire,y_trainBinaire) = shuffle(x_trainBinaire,y_trainBinaire,random_state=0)\n",
    "y_trainBinaire = tensorflow.keras.utils.to_categorical(y_trainBinaire, 2)\n",
    "\n",
    "## TEST\n",
    "#class 1: positives\n",
    "x_test1 = xTest[y_test==class1,:]\n",
    "#class 2: negatives\n",
    "x_test2 = xTest[y_test==class2,:]\n",
    "# merging the 2 classes and shuffle\n",
    "x_testBinaire = np.append(x_test1,x_test2,axis=0)\n",
    "y_testBinaire = np.append(np.full(len(x_test1),-1), np.full(len(x_test2),1))\n",
    "(x_testBinaire,y_testBinaire) = shuffle(x_testBinaire,y_testBinaire,random_state=0)\n",
    "y_testBinaire = tensorflow.keras.utils.to_categorical(y_testBinaire, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Un premier MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClasses=2\n",
    "#Let's build a simple neural network using the keras sequential method\n",
    "model = Sequential()\n",
    "#topology: input as the size of data, one hidden layer with 4 neurons and usual sigmoid activation\n",
    "model.add(Dense(4, input_dim=784, activation='sigmoid'))\n",
    "#softmax for the output using as many neurons as classes (2 in this case)\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to define the loss function for the training, the optimisation method (RMSprop) and the accuracy as a metric\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#now, let's train for real the network: only 20 epochs and batch size of 128 (so that an epoch contains 60000/128 iterations)\n",
    "model.fit(x_trainBinaire, y_trainBinaire, epochs=20, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que vaut le score F1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#is it good? we know the truth: y_testBinaire and we will compare to the output of the network\n",
    "\n",
    "score = model.evaluate(x_testBinaire,y_testBinaire)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "pred_testBinaire = np.argmax(model.predict(x_testBinaire),axis=1)\n",
    "print(pred_testBinaire.shape, y_testBinaire.shape)\n",
    "print(\"F1 score: \", f1_score(pred_testBinaire,np.argmax(y_testBinaire,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mêmes questions avec les 10 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbClasses=10 \n",
    "#Let's build a simple neural network using the keras sequential method\n",
    "model = Sequential()\n",
    "#topology: input as the size of data, one hidden layer with 20 neurons and usual sigmoid activation\n",
    "model.add(Dense(20, input_dim=784, activation='sigmoid'))\n",
    "#model.add(Dense(50, activation='sigmoid'))\n",
    "#softmax for the output using as many neurons as classes (10 in this case)\n",
    "model.add(Dense(nbClasses, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to define the loss function for the training, the optimisation method (RMSprop) and the accuracy as a metric\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#now, let's train for real the network: only 20 epochs and batch size of 128 (so that an epoch contains 60000/128 iterations)\n",
    "model.fit(xTrain, yTrain, epochs=20, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is it good? we know the truth: y_testBinaire and we will compare to the output of the network\n",
    "\n",
    "score = model.evaluate(xTest,yTest)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "pred_test = np.argmax(model.predict(xTest),axis=1)\n",
    "print(pred_test.shape,np.argmax(yTest,axis=1).shape)\n",
    "print(\"F1 score: \", f1_score(pred_test,np.argmax(yTest,axis=1), average=None))\n",
    "print(\"F1 score micro: \", f1_score(pred_test,np.argmax(yTest,axis=1), average='micro'))\n",
    "print(\"F1 score macro: \", f1_score(pred_test,np.argmax(yTest,axis=1), average='macro'))\n",
    "\n",
    "print('confusion matrix\\n',confusion_matrix(np.argmax(yTest,axis=1), pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Essayons de faire mieux ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A t-on laissé le temps à l'algorithme de converger ?\n",
    "Modifiez le nombre d'itérations. Les résultats sont-ils meilleurs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critère d'arrêt autre que le nombre d'itérations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this small example, we decided, as a default behavior, to stop after 20 epochs. Of course this value can be changed. Another way to deal with that is to use early stopping criterion. All options are described in the keras documentation. Feel free to experiment all options!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# we define a callback function that will control if the accuracy \n",
    "# on the validation set (a part of train set) is not changing more than 10-4 with a patience of 20 iterations\n",
    "# If the last accuracy value is not the best one, we still keep the last results\n",
    "# In this example, we extracted 20% of the train set for the validation set that will be used to monitor the convergence.\n",
    "\n",
    "ourCallback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "# let's learn the network again !\n",
    "# We do not know when the training will stop but no more than 2000 epochs.\n",
    "model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quel 'epoch' l'algorithme s'est-il arrêté ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution de la convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "ourCallback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "logdir = os.path.join(\"/home/lingrand/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboardCb = tensorflow.keras.callbacks.TensorBoard(logdir) #, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "historyCNN = model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[tensorboardCb,ourCallback])\n",
    "plot_history(historyCNN)\n",
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La topologie du réseau convient ?\n",
    "Ajoutez des neurones à la couche cachée ou bien augmentez le nombre de couches cachées.\n",
    "Exemple avec 2 couches cachées de 20 neurones (utilisez les lignes en les modifiant et en enlevant les commentaires):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dense(20, input_dim=784, activation='sigmoid'))\n",
    "#model.add(Dense(20, activation='sigmoid'))\n",
    "#model.add(Dense(nbClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce qu'augmenter le nombre de couches de neurones augmente les performances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Est-ce qu'augmenter le nombre de neurones par couche augmente les performances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifiez également l'activation 'sigmoid' par 'relu'. Observez-vous une différence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essayez les différents 'optimizer' disponibles. Quels sont-ils ? Observez-vous des différences ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modifiez les données en considérant FMNIST (Fashion MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
