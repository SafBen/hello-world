{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP boosting\n",
    "## les données: MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of train samples 60000\n",
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n",
      " 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"nb of train samples\",len(y_train))\n",
    "\n",
    "# affichez le nombre de données de test\n",
    "#     ....\n",
    "# affichez les 100 premiers labels de train\n",
    "print(y_train[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la classification binaire, on va choisir 2 classes de chiffres parmi les 10 classes de MNIST. Dans l'exmple ci-dessous, on va choisir les classes 4 et 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quelques imports pour la suite\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11693, 28, 28) (11693,)\n"
     ]
    }
   ],
   "source": [
    "# classe des '4'\n",
    "x_train4 = x_train[y_train==4,:]\n",
    "# classe des '8'\n",
    "x_train8 = x_train[y_train==8,:]\n",
    "\n",
    "# et on regroupe\n",
    "x_trainBinaire = np.append(x_train4,x_train8,axis=0)\n",
    "# en choisissant la classe '4' comme négative et la classe '8' comme positive\n",
    "y_trainBinaire = np.append(np.full(len(x_train4),-1), np.full(len(x_train8),1))\n",
    "\n",
    "#si vous souhaitez connaitre les dimensions obtenues\n",
    "print(x_trainBinaire.shape, y_trainBinaire.shape)\n",
    "\n",
    "#comme on a construit en séparant les classes, on mélange mais de la même façon pour x et y!\n",
    "(x_trainBinaire,y_trainBinaire) = shuffle(x_trainBinaire,y_trainBinaire,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting binaire le + simple, directement sur les données\n",
    "Pour cela, on va tout de même linéariser les images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11693, 784)\n"
     ]
    }
   ],
   "source": [
    "n = x_trainBinaire.shape[0]\n",
    "x_trainBinaire = x_trainBinaire.reshape(n,-1)\n",
    "print(x_trainBinaire.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelles sont les dimensions de x_trainBinaire ? Expliquez les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports nécessaire pour l'apprentissage par boosting:\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix on train data [[5809   33]\n",
      " [  49 5802]]\n"
     ]
    }
   ],
   "source": [
    "## apprentissage par boosting (Adaboost)\n",
    "# création de l'object boosting\n",
    "myboosting = ensemble.AdaBoostClassifier(n_estimators=50, learning_rate=1, algorithm='SAMME.R')\n",
    "# apprentissage sur les données 'train'\n",
    "myboosting.fit(x_trainBinaire,y_trainBinaire)\n",
    "# prédiction après apprentissage (on aimerait que y_predBinaire et y_trainBinaire soient identiques)\n",
    "y_predBinaire = myboosting.predict(x_trainBinaire)\n",
    "print('confusion matrix on train data',confusion_matrix(y_trainBinaire,y_predBinaire))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a affiché la matrice de confusion sur les données d'apprentissage pour voir si on avait appris correctement. Qu'en pensez-vous? Et si on modifie la variable n_estimators ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire de plus jolis affichages de la matrice de confusion. Pour cela, regardez la documentation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vous d'écrire le code nécessaire pour afficher la matrice de confusion sur les données de _test_.\n",
    "*ATTENTION*, l'apprentissage est déjà fait, on ne le refait plus (donc aucun appel à la méthode 'fit')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-28bdab4867b2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-28bdab4867b2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    A COMPLETER\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "A COMPLETER\n",
    "# prétraitement des données de test (2 classes ....)\n",
    "\n",
    "# calcul de la matrice de confusion et affichage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting sur les 10 classes de MNIST:\n",
    "à vous de jouer (toujours sur les données directement)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting binaire en utilisant les filtres de Haar\n",
    "La première étape va préparer les données avant l'algorithme de boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtres de Haar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports nécessaires\n",
    "from skimage import feature\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les filtres de Haar, soit on les génère automatiquement par la librairie, soit on les construit soi-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# génération automatique à partir de 2 types:\n",
    "#       'type-2-x' et 'type-2-y'\n",
    "# et dimensions des images: 28x28\n",
    "feat_coord, feat_type = feature.haar_like_feature_coord(28,28, ['type-2-x','type\n",
    "-2-y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de filtres? Et si on compare avec le nombre de pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation des images: on applique tous les filtres\n",
    "cpt=0\n",
    "\n",
    "for image in x_trainBinaire:\n",
    "    # calcul de l'image intégrale\n",
    "    int_image = transform.integral_image(image)\n",
    "    # calcul des filtre de Haar\n",
    "    features = feature.haar_like_feature(int_image, 0, 0, 28, 28,feature_type=fe\n",
    "at_type,feature_coord=feat_coord)\n",
    "    if cpt%1000 == 0:\n",
    "        ftrain = [features]\n",
    "    else:\n",
    "        ftrain = np.append(ftrain,[features],axis=0)\n",
    "    cpt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule précédente peut poser des problèmes de taille. Essayez d'enlever des filtres. Lesquels? Combien? A vous de voir ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autre solution, construire sa liste de filtre. Par exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_coord = np.array([list([[(0, 0), (0, 0)], [(0, 6), (0, 6)]]),\n",
    "       list([[(0, 0), (0, 6)], [(0, 13), (0, 20)]])])\n",
    "# on pourra écrire du code qui génère une liste plus complète\n",
    "feat_type = np.array(['type-2-x', 'type-2-x'])\n",
    "# puis on reprend le code ci-dessus pour l'appliquer aux images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'application des filtres de Haar aux images prend du temps. N'hésitez pas à sauvegarder les résultats afin de les utiliser plus tard. Par exemple, si vous testez plusieurs paramètres du boosting, ne recalculez pas les filtres de Haar à chaque fois. Une façon de sauvegarder puis recharger un objet en python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# sauver ftrain dans le fichier 'features.bin'\n",
    "with open('features.bin', 'wb') as output:\n",
    "        pickle.dump(ftrain, output, pickle.HIGHEST_PROTOCOL)\n",
    "# charger ftrain depuis sa sauvegarde\n",
    "with open('features.bin', 'rb') as output:\n",
    "        ftrain = pickle.load(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting binaire avec filtres de Haar\n",
    "Comparez les différents jeux de filtres.\n",
    "Comparez avec le premier boosting de ce TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à vous !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting 10 classes avec filtres de Haar\n",
    "Mêmes questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
